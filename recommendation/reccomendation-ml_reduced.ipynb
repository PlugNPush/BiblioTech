{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Explication : L'ago doit prédire les notes d'un utilisateur pour des livres qu'il n'a pas encore notés. Ce système prend en compte les notes que l'utilisateur a attribuées à ses livres pour faire des prédictions. Les notes qu'un utilisateur a attribuées à ses livres sont utilisées pour faire des prédictions sur les livres qu'il pourrait aimer à l'avenir. De plus, parce que la SVD prend en compte les notes de tous les utilisateurs, les prédictions sont également influencées par les préférences des utilisateurs similaires"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T03:15:51.004181Z","iopub.status.busy":"2023-05-14T03:15:51.003354Z","iopub.status.idle":"2023-05-14T03:15:51.010627Z","shell.execute_reply":"2023-05-14T03:15:51.008898Z","shell.execute_reply.started":"2023-05-14T03:15:51.004144Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\loicc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n","  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import recall_score\n","from scipy import stats\n","from scipy.sparse import csr_matrix\n","from scipy.sparse.linalg import svds\n","\n","import ast\n","from sqlalchemy import create_engine, text\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import linear_kernel\n","from fuzzywuzzy import process, fuzz\n","from IPython.display import clear_output"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## PREPROCESSING"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Title</th>\n","      <th>authors</th>\n","      <th>categories</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Old Brooklyn Heights; New York's First Suburb.</td>\n","      <td>['Clay Lancaster']</td>\n","      <td>['Architecture, Domestic']</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>The Crown of Anavrea</td>\n","      <td>['Rachel Rossano']</td>\n","      <td>['Fiction']</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>The Allegheny, (Rivers of America)</td>\n","      <td>['Frederick Way']</td>\n","      <td>['Allegheny River (Pa. and N.Y.)']</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>The natural house</td>\n","      <td>['Daniel D. Chiras']</td>\n","      <td>['House &amp; Home']</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Beyond the Big Test: Noncognitive Assessment i...</td>\n","      <td>['William E. Sedlacek']</td>\n","      <td>['Education']</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               Title                  authors   \n","0     Old Brooklyn Heights; New York's First Suburb.       ['Clay Lancaster']  \\\n","1                               The Crown of Anavrea       ['Rachel Rossano']   \n","2                 The Allegheny, (Rivers of America)        ['Frederick Way']   \n","3                                  The natural house     ['Daniel D. Chiras']   \n","4  Beyond the Big Test: Noncognitive Assessment i...  ['William E. Sedlacek']   \n","\n","                           categories  \n","0          ['Architecture, Domestic']  \n","1                         ['Fiction']  \n","2  ['Allegheny River (Pa. and N.Y.)']  \n","3                    ['House & Home']  \n","4                       ['Education']  "]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["book_data = pd.read_csv(\"books_metadata_Amazon_reduced.csv\", delimiter=',', on_bad_lines='skip')\n","book_data = book_data[['Title', 'authors', 'categories']] # keep the Title, authors and categories from the columns\n","book_data.head()"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Title</th>\n","      <th>authors</th>\n","      <th>categories</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Old Brooklyn Heights; New York's First Suburb.</td>\n","      <td>Clay Lancaster</td>\n","      <td>Architecture, Domestic</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>The Crown of Anavrea</td>\n","      <td>Rachel Rossano</td>\n","      <td>Fiction</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>The Allegheny, (Rivers of America)</td>\n","      <td>Frederick Way</td>\n","      <td>Allegheny River (Pa. and N.Y.)</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>The natural house</td>\n","      <td>Daniel D. Chiras</td>\n","      <td>House &amp; Home</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Beyond the Big Test: Noncognitive Assessment i...</td>\n","      <td>William E. Sedlacek</td>\n","      <td>Education</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               Title              authors   \n","0     Old Brooklyn Heights; New York's First Suburb.       Clay Lancaster  \\\n","1                               The Crown of Anavrea       Rachel Rossano   \n","2                 The Allegheny, (Rivers of America)        Frederick Way   \n","3                                  The natural house     Daniel D. Chiras   \n","4  Beyond the Big Test: Noncognitive Assessment i...  William E. Sedlacek   \n","\n","                       categories  \n","0          Architecture, Domestic  \n","1                         Fiction  \n","2  Allegheny River (Pa. and N.Y.)  \n","3                    House & Home  \n","4                       Education  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# Function to convert a list into a string\n","def list_to_string(list):\n","    return ', '.join(list)\n","\n","def str_to_list(list_str):\n","    if isinstance(list_str, str):\n","        return ast.literal_eval(list_str)\n","    else:\n","        return []\n","\n","# Replace NaN with empty strings\n","book_data['authors'].fillna('[]', inplace=True)\n","book_data['categories'].fillna('[]', inplace=True)\n","\n","# Convert strings that look like lists into actual lists\n","book_data['authors'] = book_data['authors'].apply(str_to_list)\n","book_data['categories'] = book_data['categories'].apply(str_to_list)\n","\n","# Convert the lists into strings\n","book_data['authors'] = book_data['authors'].apply(list_to_string)\n","book_data['categories'] = book_data['categories'].apply(list_to_string)\n","\n","book_data.head()\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T03:18:26.242013Z","iopub.status.busy":"2023-05-14T03:18:26.241585Z","iopub.status.idle":"2023-05-14T03:18:54.547477Z","shell.execute_reply":"2023-05-14T03:18:54.546459Z","shell.execute_reply.started":"2023-05-14T03:18:26.241983Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ProductId</th>\n","      <th>UserId</th>\n","      <th>title</th>\n","      <th>Score</th>\n","      <th>Time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0782141706</td>\n","      <td>A2W9ZSNBCJAUUD</td>\n","      <td>CCNA Certification Kit (2nd Edition)</td>\n","      <td>5.0</td>\n","      <td>981504000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>B0006C97LK</td>\n","      <td>AMI0C2C9QS8U3</td>\n","      <td>Howl, and other poems (The Pocket poets series)</td>\n","      <td>5.0</td>\n","      <td>1101772800</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>080694031X</td>\n","      <td>A2MXH04RLOK14U</td>\n","      <td>Bonsai for Beginners</td>\n","      <td>2.0</td>\n","      <td>1035504000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0970219083</td>\n","      <td>A1PICWXVZHP61T</td>\n","      <td>Not Without Anna</td>\n","      <td>5.0</td>\n","      <td>1051228800</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0582418224</td>\n","      <td>A191G499E1OUIW</td>\n","      <td>The Moonstone (Penguin Readers, Level 6)</td>\n","      <td>5.0</td>\n","      <td>1317254400</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    ProductId          UserId   \n","0  0782141706  A2W9ZSNBCJAUUD  \\\n","1  B0006C97LK   AMI0C2C9QS8U3   \n","2  080694031X  A2MXH04RLOK14U   \n","3  0970219083  A1PICWXVZHP61T   \n","4  0582418224  A191G499E1OUIW   \n","\n","                                             title  Score        Time  \n","0             CCNA Certification Kit (2nd Edition)    5.0   981504000  \n","1  Howl, and other poems (The Pocket poets series)    5.0  1101772800  \n","2                             Bonsai for Beginners    2.0  1035504000  \n","3                                 Not Without Anna    5.0  1051228800  \n","4         The Moonstone (Penguin Readers, Level 6)    5.0  1317254400  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# consider on user_id, book_id, and ratings\n","df = pd.read_csv('Books_Amazon_reduced.csv')\n","df = df[['Id','User_id','Title','review/score', 'review/time']]\n","df.rename(columns={'Id':'ProductId','User_id':'UserId','review/time':'Time','Title':'title','review/score':'Score'},inplace=True)\n","df.head()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["(99009, 5)"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df.shape"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# FUSION DES DONNEES\n","df['title'] = df['title'].str.strip().str.lower()\n","book_data['Title'] = book_data['Title'].str.strip().str.lower()\n","\n","# Merge the DataFrames on the titles\n","df = df.merge(book_data, how='left', left_on='title', right_on='Title')\n","\n","# Supprimez la colonne des titres en double\n","df = df.drop(columns=['Title'])\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ProductId</th>\n","      <th>UserId</th>\n","      <th>title</th>\n","      <th>Score</th>\n","      <th>Time</th>\n","      <th>authors</th>\n","      <th>categories</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0782141706</td>\n","      <td>A2W9ZSNBCJAUUD</td>\n","      <td>ccna certification kit (2nd edition)</td>\n","      <td>5.0</td>\n","      <td>981504000</td>\n","      <td>Todd Lammle</td>\n","      <td>Computers</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>B0006C97LK</td>\n","      <td>AMI0C2C9QS8U3</td>\n","      <td>howl, and other poems (the pocket poets series)</td>\n","      <td>5.0</td>\n","      <td>1101772800</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>080694031X</td>\n","      <td>A2MXH04RLOK14U</td>\n","      <td>bonsai for beginners</td>\n","      <td>2.0</td>\n","      <td>1035504000</td>\n","      <td>Bonsai Empire</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0970219083</td>\n","      <td>A1PICWXVZHP61T</td>\n","      <td>not without anna</td>\n","      <td>5.0</td>\n","      <td>1051228800</td>\n","      <td>Vicki M. Taylor</td>\n","      <td>Fiction</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0582418224</td>\n","      <td>A191G499E1OUIW</td>\n","      <td>the moonstone (penguin readers, level 6)</td>\n","      <td>5.0</td>\n","      <td>1317254400</td>\n","      <td>Wilkie Collins</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>101421</th>\n","      <td>B000P4VYRO</td>\n","      <td>NaN</td>\n","      <td>speaker for the dead</td>\n","      <td>5.0</td>\n","      <td>943315200</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>101422</th>\n","      <td>B000MS0A0A</td>\n","      <td>A7YRO6JIVVG7D</td>\n","      <td>zen and the art of motorcycle maintenance</td>\n","      <td>5.0</td>\n","      <td>1195344000</td>\n","      <td>Robert M. Pirsig</td>\n","      <td>Philosophy</td>\n","    </tr>\n","    <tr>\n","      <th>101423</th>\n","      <td>B000G643YM</td>\n","      <td>A2I89G8EPYMZ62</td>\n","      <td>little women</td>\n","      <td>5.0</td>\n","      <td>1355961600</td>\n","      <td>Louisa May Alcott</td>\n","      <td>Fiction</td>\n","    </tr>\n","    <tr>\n","      <th>101424</th>\n","      <td>B00005J6VH</td>\n","      <td>NaN</td>\n","      <td>bridget jones's diary</td>\n","      <td>5.0</td>\n","      <td>897868800</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>101425</th>\n","      <td>0316702781</td>\n","      <td>A1ZJCGAYL1MWI7</td>\n","      <td>saying goodbye to lulu</td>\n","      <td>5.0</td>\n","      <td>1312070400</td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>101426 rows × 7 columns</p>\n","</div>"],"text/plain":["         ProductId          UserId   \n","0       0782141706  A2W9ZSNBCJAUUD  \\\n","1       B0006C97LK   AMI0C2C9QS8U3   \n","2       080694031X  A2MXH04RLOK14U   \n","3       0970219083  A1PICWXVZHP61T   \n","4       0582418224  A191G499E1OUIW   \n","...            ...             ...   \n","101421  B000P4VYRO             NaN   \n","101422  B000MS0A0A   A7YRO6JIVVG7D   \n","101423  B000G643YM  A2I89G8EPYMZ62   \n","101424  B00005J6VH             NaN   \n","101425  0316702781  A1ZJCGAYL1MWI7   \n","\n","                                                  title  Score        Time   \n","0                  ccna certification kit (2nd edition)    5.0   981504000  \\\n","1       howl, and other poems (the pocket poets series)    5.0  1101772800   \n","2                                  bonsai for beginners    2.0  1035504000   \n","3                                      not without anna    5.0  1051228800   \n","4              the moonstone (penguin readers, level 6)    5.0  1317254400   \n","...                                                 ...    ...         ...   \n","101421                             speaker for the dead    5.0   943315200   \n","101422        zen and the art of motorcycle maintenance    5.0  1195344000   \n","101423                                     little women    5.0  1355961600   \n","101424                            bridget jones's diary    5.0   897868800   \n","101425                           saying goodbye to lulu    5.0  1312070400   \n","\n","                  authors  categories  \n","0             Todd Lammle   Computers  \n","1                     NaN         NaN  \n","2           Bonsai Empire              \n","3         Vicki M. Taylor     Fiction  \n","4          Wilkie Collins              \n","...                   ...         ...  \n","101421                NaN         NaN  \n","101422   Robert M. Pirsig  Philosophy  \n","101423  Louisa May Alcott     Fiction  \n","101424                NaN         NaN  \n","101425                                 \n","\n","[101426 rows x 7 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Data Preprocessing"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T03:18:54.552040Z","iopub.status.busy":"2023-05-14T03:18:54.549342Z","iopub.status.idle":"2023-05-14T03:18:55.508197Z","shell.execute_reply":"2023-05-14T03:18:55.507193Z","shell.execute_reply.started":"2023-05-14T03:18:54.552009Z"},"trusted":true},"outputs":[],"source":["#lots of fields where user is NaN\n","df = df.dropna(subset=['UserId'])"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T03:29:25.884910Z","iopub.status.busy":"2023-05-14T03:29:25.884497Z","iopub.status.idle":"2023-05-14T03:29:28.680736Z","shell.execute_reply":"2023-05-14T03:29:28.679764Z","shell.execute_reply.started":"2023-05-14T03:29:25.884881Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Size of 'ProductId' column: 82185\n","Size of 'UserId' column: 82185\n","Size of 'ProductId' column: 9094\n","Size of 'UserId' column: 9094\n"]}],"source":["print(\"Size of 'ProductId' column:\", len(df['ProductId']))\n","print(\"Size of 'UserId' column:\", len(df['UserId']))\n","\n","# Define the threshold values\n","product_id_threshold = 10\n","user_id_threshold = 2\n","\n","# Count the occurrences of ProductId and UserId\n","product_id_counts = df['ProductId'].value_counts()\n","user_id_counts = df['UserId'].value_counts()\n","\n","# Filter out rows below the threshold\n","filtered_df = df[(df['ProductId'].isin(product_id_counts[product_id_counts >= product_id_threshold].index)) &\n","                 (df['UserId'].isin(user_id_counts[user_id_counts >= user_id_threshold].index))]\n","\n","print(\"Size of 'ProductId' column:\", len(filtered_df['ProductId']))\n","print(\"Size of 'UserId' column:\", len(filtered_df['UserId']))"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T03:29:30.614453Z","iopub.status.busy":"2023-05-14T03:29:30.614101Z","iopub.status.idle":"2023-05-14T03:29:54.883846Z","shell.execute_reply":"2023-05-14T03:29:54.882883Z","shell.execute_reply.started":"2023-05-14T03:29:30.614425Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(4513, 1093)\n"]},{"data":{"text/plain":["array([[5., 0., 0., ..., 0., 0., 0.],\n","       [0., 4., 0., ..., 0., 0., 0.],\n","       [0., 0., 4., ..., 0., 0., 0.],\n","       ...,\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.]])"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# Get unique UserIds and ProductIds\n","unique_user_ids = filtered_df['UserId'].unique()\n","unique_product_ids = filtered_df['ProductId'].unique() #unique ids for books are less\n","\n","user_id_to_index = {user_id: index for index, user_id in enumerate(unique_user_ids)}\n","product_id_to_index = {product_id: index for index, product_id in enumerate(unique_product_ids)}\n","\n","# clean matrix\n","matrix = np.zeros((len(unique_user_ids), len(unique_product_ids)))\n","\n","# users as rows, books as columns with their ratings\n","for _, row in filtered_df.iterrows():\n","    user_id = row['UserId']\n","    product_id = row['ProductId']\n","    score = row['Score']\n","    \n","    user_index = user_id_to_index[user_id]\n","    product_index = product_id_to_index[product_id]\n","    \n","    if matrix[user_index][product_index] < score:\n","        matrix[user_index][product_index] = score\n","print(matrix.shape)\n","matrix"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Z-Scoring"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T03:44:54.661743Z","iopub.status.busy":"2023-05-14T03:44:54.661324Z","iopub.status.idle":"2023-05-14T03:44:55.305638Z","shell.execute_reply":"2023-05-14T03:44:55.304536Z","shell.execute_reply.started":"2023-05-14T03:44:54.661704Z"},"trusted":true},"outputs":[],"source":["matrix = stats.zscore(matrix, axis=0)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Evaluation"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Evaluation de la performance des recommandation"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T03:30:29.142468Z","iopub.status.busy":"2023-05-14T03:30:29.142111Z","iopub.status.idle":"2023-05-14T03:30:29.156050Z","shell.execute_reply":"2023-05-14T03:30:29.153831Z","shell.execute_reply.started":"2023-05-14T03:30:29.142437Z"},"trusted":true},"outputs":[],"source":["def calculate_mse(predicted_matrix, test_matrix):\n","    num_users = min(predicted_matrix.shape[0], test_matrix.shape[0])\n","    num_items = min(predicted_matrix.shape[1], test_matrix.shape[1])\n","    mse = np.mean((predicted_matrix[:num_users, :num_items] - test_matrix[:num_users, :num_items]) ** 2)\n","    return mse\n","\n","def calculate_f1_score(recall, precision):\n","    if recall + precision == 0:\n","        return 0\n","    f1_score = 2 * (precision * recall) / (precision + recall)\n","    return f1_score\n","\n","def precision_at_k(actual_matrix, predicted_matrix, k, threshold):\n","    binary_predicted_matrix = predicted_matrix >= threshold\n","    \n","    precision = []\n","    for i in range(len(actual_matrix)):\n","        actual_indices = np.where(actual_matrix[i] >= threshold)[0]\n","        predicted_indices = np.argsort(~binary_predicted_matrix[i])[:k]\n","        common_indices = np.intersect1d(actual_indices, predicted_indices)\n","        precision.append(len(common_indices) / len(predicted_indices))\n","    \n","    return np.mean(precision)\n","\n","def recall_at_k(true_matrix, pred_matrix, k, threshold):\n","    pred_matrix_sorted = np.argsort(pred_matrix, axis=1)[:, ::-1][:, :k]\n","    recall_scores = []\n","    for i in range(len(true_matrix)):\n","        true_positives = len(set(pred_matrix_sorted[i]).intersection(set(np.where(true_matrix[i] >= threshold)[0])))\n","        actual_positives = len(np.where(true_matrix[i] >= threshold)[0])\n","        if actual_positives > 0:\n","            recall_scores.append(true_positives / actual_positives)\n","    recall = np.mean(recall_scores)\n","    return recall"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# SVD"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["système de recommandation basé sur la factorisation de matrices, en particulier la décomposition en valeurs singulières"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T03:45:36.914070Z","iopub.status.busy":"2023-05-14T03:45:36.913356Z","iopub.status.idle":"2023-05-14T03:49:47.502740Z","shell.execute_reply":"2023-05-14T03:49:47.500694Z","shell.execute_reply.started":"2023-05-14T03:45:36.914038Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Set Mean Squared Error (MSE): 0.21658291039866834\n","Test Set Mean Squared Error (MSE): 0.6538035553198843\n"]}],"source":["def split_train_test(matrix, test_size=0.2, random_state=42):\n","    train_matrix, test_matrix = train_test_split(matrix, test_size=test_size, random_state=random_state)\n","    return train_matrix, test_matrix\n","\n","def calculate_svd(train_matrix, k=600):\n","    train_sparse = csr_matrix(train_matrix)\n","    # Perform SVD on the sparse matrix\n","    U_train, S_train, VT_train = svds(train_sparse, k=k)\n","    # Reverse the singular values, columns of U_train, and rows of VT_train\n","    S_train_k = np.diag(S_train[::-1])\n","    U_train_k = U_train[:, ::-1]\n","    VT_train_k = VT_train[::-1, :]\n","    \n","    return U_train_k, S_train_k, VT_train_k\n","\n","train_matrix, test_matrix = split_train_test(matrix)\n","\n","# training set\n","U_train, S_train, VT_train = calculate_svd(train_matrix)\n","U_train_pred = np.dot(train_matrix, VT_train.T)\n","train_pred_matrix = np.dot(U_train_pred, VT_train)\n","\n","# Make predictions for the test set\n","U_test_pred = np.dot(test_matrix, VT_train.T)\n","predicted_matrix = np.dot(U_test_pred, VT_train)\n","\n","# Calculate MSE \n","train_mse = calculate_mse(train_matrix, train_pred_matrix)\n","test_mse = calculate_mse(test_matrix, predicted_matrix)\n","\n","print(\"Train Set Mean Squared Error (MSE):\", train_mse)\n","print(\"Test Set Mean Squared Error (MSE):\", test_mse)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T03:51:27.289276Z","iopub.status.busy":"2023-05-14T03:51:27.288900Z","iopub.status.idle":"2023-05-14T03:51:28.118924Z","shell.execute_reply":"2023-05-14T03:51:28.117875Z","shell.execute_reply.started":"2023-05-14T03:51:27.289247Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["RMSE (training):  0.465384690765251\n","RMSE (test):  0.8085811989651283\n","Precision @ 10:  0.14451827242524917\n","Recall @ 10: 0.9324947070948246\n","F1 Score: 0.2502523677571354\n"]}],"source":["# Calculate Precision at k for the test set\n","precision = precision_at_k(test_matrix, predicted_matrix, k=10, threshold=3)\n","\n","# Calculate Recall at k for the test set\n","recall = recall_at_k(test_matrix, predicted_matrix, k=10, threshold=3)\n","\n","# Calculate F1 score\n","f1_score = calculate_f1_score(recall, precision)\n","print(\"RMSE (training): \", np.sqrt(train_mse) )\n","print(\"RMSE (test): \", np.sqrt(test_mse))\n","print(\"Precision @ 10: \", precision)\n","print(\"Recall @ 10:\", recall)\n","print(\"F1 Score:\", f1_score)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Output MySQL USER DATA"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["def get_user_data(user_email):\n","    # Connect to the database\n","    engine = create_engine('mysql://root:771600@localhost:3306/db_master_project') # Change the password accordingly !!!!\n","\n","    # Load user's read and liked books from the database\n","    query = text(f\"SELECT * FROM user WHERE email = '{user_email}';\")\n","    user_data = pd.read_sql_query(query, engine)\n","    \n","    return user_data\n","user_data = get_user_data('john.doe@example.com')"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["def get_user_books(user_email):\n","    \"\"\" Récupère les livres d'un utilisateur à partir de la base de données \"\"\"\n","    engine = create_engine('mysql://username:password@localhost:3306/db_master_project')\n","    user_books_query = text(f\"SELECT * FROM book WHERE owner = '{user_email}';\")\n","    user_books = pd.read_sql_query(user_books_query, engine)\n","    #user_books = user_books[user_books['rating'].between(0, 5)]\n","    # Prendre en compte la casse et les espaces supplémentaires\n","    user_books['title'] = user_books['title'].str.strip().str.lower()\n","    return user_books\n","\n","user_books = get_user_books('john.doe@example.com')"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["def recommend_books_for_new_user(user_books, n_recommendations):\n","    user_matrix = np.zeros(len(unique_product_ids))\n","\n","    for _, book in user_books.iterrows():\n","        title = book['title']\n","        rating = book['rating']\n","        closest_match = process.extractOne(title, list(product_id_to_index.keys()))\n","        if closest_match[1] < 80:  # Ignore the match if the similarity score is less than 80\n","            continue\n","        closest_title = closest_match[0]\n","        product_id_values = df[df['title'] == closest_title]['ProductId'].values\n","        if product_id_values.size == 0:  # The book does not exist in df\n","            continue\n","        product_id = product_id_values[0]\n","        if product_id in product_id_to_index:\n","            product_index = product_id_to_index[product_id]\n","            user_matrix[product_index] = rating\n","    user_embedding = np.dot(user_matrix, VT_train.T)\n","    similarity_scores = VT_train.T.dot(user_embedding)\n","    sorted_indices = similarity_scores.argsort()[::-1]\n","    top_relevant_indices = sorted_indices[:n_recommendations]\n","    recommended_product_ids = [list(product_id_to_index.keys())[list(product_id_to_index.values()).index(idx)] for idx in top_relevant_indices]\n","    recommended_books = df.loc[df['ProductId'].isin(recommended_product_ids), 'title'].unique().tolist()\n","    return recommended_books\n"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Recommended Books:\n","like water for chocolate: a novel in monthly installments, withrecipes, romances, and home remedies\n","the creature from jekyll island: a second look at the federal reserve\n","goodnight moon\n","the tao of pooh\n","the book of three\n","like water for chocolate\n","dress your family in corduroy and denim\n","my side of the mountain\n","echo park (signed)\n","tea rose\n"]}],"source":["# RESULTATS DES RECOMMANDATIONS\n","user_books = get_user_books('john.doe@example.com')\n","recommended_books = recommend_books_for_new_user(user_books,10)\n","print(\"Recommended Books:\")\n","for book in recommended_books:\n","    print(book)\n"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/plain":["['like water for chocolate: a novel in monthly installments, withrecipes, romances, and home remedies',\n"," 'the creature from jekyll island: a second look at the federal reserve',\n"," 'goodnight moon',\n"," 'the tao of pooh',\n"," 'the book of three',\n"," 'like water for chocolate',\n"," 'dress your family in corduroy and denim',\n"," 'my side of the mountain',\n"," 'echo park (signed)',\n"," 'tea rose']"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["recommended_books"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["N'hésitez pas à contacter à toute heure de la journée ou de la nuit Logan en cas de problème: logan.le.lay@efrei.net"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## TEST SUR UTILISATEUR DEJA PRÉSENT"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T03:51:40.873994Z","iopub.status.busy":"2023-05-14T03:51:40.873601Z","iopub.status.idle":"2023-05-14T03:51:40.881140Z","shell.execute_reply":"2023-05-14T03:51:40.880143Z","shell.execute_reply.started":"2023-05-14T03:51:40.873965Z"},"trusted":true},"outputs":[],"source":["def fetch_relevant_items_for_user(user_id, relevant_items=5):\n","    # Get the index of the user\n","    user_index = user_id_to_index[user_id]\n","    user_embedding = U_train[user_index, :]\n","    \n","    similarity_scores = VT_train.T.dot(user_embedding)\n","\n","    sorted_indices = similarity_scores.argsort()[::-1]\n","    top_relevant_indices = sorted_indices[:relevant_items]\n","    \n","    relevant_items = [list(product_id_to_index.keys())[list(product_id_to_index.values()).index(idx)] for idx in top_relevant_indices]\n","    relevant_titles = df.loc[df['ProductId'].isin(relevant_items), 'title'].tolist()\n","    \n","    # Remove any duplicate titles\n","    unique_relevant_titles = list(set(relevant_titles))\n","    \n","    # Get the final set of relevant items without duplicate titles\n","    final_relevant_items = []\n","    for title in unique_relevant_titles:\n","        final_relevant_items.append(title)\n","    \n","    return final_relevant_items"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T03:51:42.829300Z","iopub.status.busy":"2023-05-14T03:51:42.828955Z","iopub.status.idle":"2023-05-14T03:51:43.572790Z","shell.execute_reply":"2023-05-14T03:51:43.571781Z","shell.execute_reply.started":"2023-05-14T03:51:42.829274Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'\\nuser_id = [\"A30C4HNZBZYDI2\", \"A3OWUSU9RG4NMF\", \"A2BIFGERNRDLBB\"] \\ntop_n = 5\\n\\nfor id in user_id:\\n    relevant_items = fetch_relevant_items_for_user(id, top_n)\\n    print(f\"User: {id}\")\\n    print(\"Relevant Items:\")\\n    for i, item in enumerate(relevant_items):\\n        print(f\"{i+1}. {item}\")\\n    print()\\n    '"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","user_id = [\"A30C4HNZBZYDI2\", \"A3OWUSU9RG4NMF\", \"A2BIFGERNRDLBB\"] \n","top_n = 5\n","\n","for id in user_id:\n","    relevant_items = fetch_relevant_items_for_user(id, top_n)\n","    print(f\"User: {id}\")\n","    print(\"Relevant Items:\")\n","    for i, item in enumerate(relevant_items):\n","        print(f\"{i+1}. {item}\")\n","    print()\n","    \"\"\""]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":4}
